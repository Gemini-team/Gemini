#include "UnityCG.cginc"
#include "UnityShaderVariables.cginc"
#include "../Core/ZBuffer/DepthCameras_CS.compute"
#include "../Core/RNG_CS.compute"

// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain
#pragma kernel RNG_Initialize

struct lidarFields
{
	float3 position;
	float intensity;
	uint ring;
	float time;
};

RWStructuredBuffer<float3> lines;
RWStructuredBuffer<lidarFields> LidarData;
RWStructuredBuffer<uint2> sphericalPixelCoordinates;
//RWStructuredBuffer<float> Debug_vector_main;
int N_theta;
int N_phi;
float rayDropProbability;

[numthreads(1024, 1, 1)]
void CSMain(uint3 id : SV_DispatchThreadID)
{
	int cameraID = id.x / (N_theta*N_phi);
	uint2 coord = sphericalPixelCoordinates[id.x % (N_theta*N_phi)];
	coord.x += ImageWidthRes * cameraID;

	float3 pixelCoordinates = ImagesToCartesian(coord); // output in the left handed [right, up, forward] unity frame

	// FIXME this is dreadful... This is an ad hoc removal of points above 3m in height, in the local lidar frame..
	// this made sense for removing points at the ocean surface for the upside down (3m above sea level) lidars on mA2
	// HOWEVER, we have no business trying to landmask (or watermask hah) points in the local lidar frame
	if (pixelCoordinates.y > 3.00) {
		pixelCoordinates = float3(0, 0, 0);
	}

	// Raydrop
	if (RandomFloat(id.x) < rayDropProbability) {
		pixelCoordinates = float3(0, 0, 0);
	}

	if (id.x <= N_phi * N_theta*NrOfImages) {
		// This is the output shown in Unity	
		lines[id.x] = pixelCoordinates; // left handed: [right, up, forward]
		// This will be used for sending of pointclouds
		// Transform to the LiDAR specific coordinate system
		LidarData[id.x].position = float3(pixelCoordinates.z, -pixelCoordinates.x, pixelCoordinates.y); // right handed: [forward, left, up] frame
		LidarData[id.x].intensity = 6;
		LidarData[id.x].ring = int(N_phi*(float(coord.y)/float(ImageHeightRes))) ;
		LidarData[id.x].time = 1.0;
	}
}